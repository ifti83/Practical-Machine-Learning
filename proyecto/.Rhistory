prp(treeModel) # fast plot
#Answers
#This was not created by me. This is the function that appeared to submit the answers.
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
x <- evaluation_data
x <- x[feature_set[feature_set!='classe']]
answers <- predict(rf, newdata=x)
answers
pml_write_files(answers)
prp(treeModel)
treeModel
rpart
packages <- c("data.table", "caret", "randomForest", "foreach", "doParallel", "rpart", "rpart.plot")
load(packages)
treeModel <- rpart(y ~ ., data=trainData, method="class")
prp(treeModel) # fast plot
treeModel <- rpart(y ~ ., data=trainData, method="class")
treeModel <- rpart(y ~ ., data=training, method="class")
prp(treeModel) # fast plot
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "doParallel", "rpart", "rpart.plot")
load(packages)
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training_data)
cleantraining <- training_data[, -which(names(training_data) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining = cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
training_data <- cleantraining
for(i in c(8:ncol(training_data)-1)) {training_data[,i] = as.numeric(as.character(training_data[,i]))}
for(i in c(8:ncol(evaluation_data)-1)) {evaluation_data[,i] = as.numeric(as.character(evaluation_data[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
feature_set <- colnames(training_data[colSums(is.na(training_data)) == 0])[-(1:7)]
model_data <- training_data[feature_set]
feature_set #now we have the model data built from our feature set.
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot")
load(packages)
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training_data)
cleantraining <- training_data[, -which(names(training_data) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining = cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
training_data <- cleantraining
for(i in c(8:ncol(training_data)-1)) {training_data[,i] = as.numeric(as.character(training_data[,i]))}
for(i in c(8:ncol(evaluation_data)-1)) {evaluation_data[,i] = as.numeric(as.character(evaluation_data[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
feature_set <- colnames(training_data[colSums(is.na(training_data)) == 0])[-(1:7)]
model_data <- training_data[feature_set]
feature_set #now we have the model data built from our feature set.
idx <- createDataPartition(y=model_data$classe, p=0.6, list=FALSE )
training <- model_data[idx,]
testing <- model_data[-idx,]
controlRf <- trainControl(method="cv", 5)
modelRf <- train(classe ~ ., data=training, method="rf", trControl=controlRf, ntree=250)
modelRf
predictRf <- predict(modelRf, testData)
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=controlRf, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, testCleaned[, -length(names(testCleaned))])
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot")
load(packages)
training_data <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation_data <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training_data)
cleantraining <- training_data[, -which(names(training_data) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining = cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
training <- cleantraining
for(i in c(8:ncol(training)-1)) {training[,i] = as.numeric(as.character(training[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
feature_set <- colnames(training[colSums(is.na(training)) == 0])[-(1:7)]
model_data <- training[feature_set]
feature_set #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=model_data$classe, p=0.6, list=FALSE )
training <- model_data[idx,]
testing <- model_data[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=controlRf, ntree=250)
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training_data)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
feature_set <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
model_data <- cleantraining[feature_set]
feature_set #now we have the model data built from our feature set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[feature_set]
featureset #now we have the model data built from our feature set.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
training <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
accuracy
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training_data)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[feature_set]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
training <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, testCleaned[, -length(names(testCleaned))])
result
result <- predict(model, cleantraining[, -length(names(cleantraining))])
result
corrPlot <- cor(trainData[, -length(names(trainData))])
corrPlot <- cor(trainData[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
corrPlot <- cor(trainData[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
corrPlot <- cor(trainData[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
corrPlot <- cor(trainData[, -length(names(cleantraining))])
corrPlot <- cor(cleantraining[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel) # fast plot
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
x <- evaluation_data
x <- x[feature_set[feature_set!='classe']]
answers <- predict(rf, newdata=x)
answers
pml_write_files(answers)
accuracy
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
cleantraining <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
cleantraining <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, training[, -length(names(training))])
result
corrPlot <- cor(cleantraining[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel) # fast plot
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- predict(rf, newdata=x[featureset[featureset!='classe']])
answers
pml_write_files(answers)
answers <- predict(model, newdata=x[featureset[featureset!='classe']])
answers
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- predict(model, newdata=x[featureset[featureset!='classe']])
answers
pml_write_files(answers)
answers <- predict(model, newdata=featureset[featureset!='classe'])
answers <- predict(model, newdata=[featureset[featureset!='classe']])
answers <- predict(model, newdata=featureset[featureset!='classe'])
answers <- predict(model, featureset[featureset!='classe'])
featureset[featureset!='classe']
answers <- predict(model, featureset[featureset!='classe'])
answers <- predict(model, featureset[featureset!='classe'])
answers <- predict(model, newdata=x[featureset[featureset!='classe']])
answers
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
cleantraining <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, training[, -length(names(training))])
result
corrPlot <- cor(cleantraining[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel) # fast plot
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- predict(model, newdata=x[featureset[featureset!='classe']])
answers
answers <- predict(model, newdata=[featureset[featureset!='classe']])
answers <- predict(model, newdata=featureset[featureset!='classe'])
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- result
answers
pml_write_files(answers)
#Reading and Cleaning Data
#Read both training and testing instances. I have used a function named LOAD to load the packages that I will use later.
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
evaluation <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"," ", "", "NA", "NAs", "NULL"))
#I need to drop columns with NAs, drop highly correlated variables and drop variables with 0 (or approx to 0) variance.
str(training)
cleantraining <- training[, -which(names(training) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window"))]
cleantraining = cleantraining[, colSums(is.na(cleantraining)) == 0] #this drops columns with NAs
zerovariance =nearZeroVar(cleantraining[sapply(cleantraining, is.numeric)], saveMetrics=TRUE)
cleantraining = cleantraining[, zerovariance[, 'nzv'] == 0] #to remove 0 or near to 0 variance variables
correlationmatrix <- cor(na.omit(cleantraining[sapply(cleantraining, is.numeric)]))
dim(correlationmatrix)
correlationmatrixdegreesoffreedom <- expand.grid(row = 1:52, col = 1:52)
correlationmatrixdegreesoffreedom$correlation <- as.vector(correlationmatrix) #this returns the correlation matrix in matrix format
removehighcorrelation <- findCorrelation(correlationmatrix, cutoff = .7, verbose = TRUE)
cleantraining <- cleantraining[, -removehighcorrelation] #this removes highly correlated variables (in psychometric theory .7+ correlation is a high correlation)
for(i in c(8:ncol(cleantraining)-1)) {cleantraining[,i] = as.numeric(as.character(cleantraining[,i]))}
for(i in c(8:ncol(evaluation)-1)) {evaluation[,i] = as.numeric(as.character(evaluation[,i]))} #Some columns were blank, hence are dropped. I will use a set that only includes complete columns. I also remove user name, timestamps and windows to have a light data set.
featureset <- colnames(cleantraining[colSums(is.na(cleantraining)) == 0])[-(1:7)]
modeldata <- cleantraining[featureset]
featureset #now we have the model data built from our feature set.
##Cross-Validation
#I need to split the sample in two samples. This is to divide training and testing for cross-validation.
idx <- createDataPartition(y=modeldata$classe, p=0.6, list=FALSE )
cleantraining <- modeldata[idx,]
testing <- modeldata[-idx,]
control <- trainControl(method="cv", 5)
model <- train(classe ~ ., data=training, method="rf", trControl=control, ntree=250)
model
predict <- predict(model, testing)
confusionMatrix(testing$classe, predict)
accuracy <- postResample(predict, testing$classe)
accuracy
result <- predict(model, training[, -length(names(training))])
result
corrPlot <- cor(cleantraining[, -length(names(cleantraining))])
corrplot(corrPlot, method="color")
treeModel <- rpart(classe ~ ., data=cleantraining, method="class")
prp(treeModel) # fast plot
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- result
answers
result
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
answers <- predict(model, newdata=x[featureset[featureset!='classe']])
answers
pml_write_files(answers)
