options("viewer"=NULL)
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("devtools", "knitr", "xlsx")
ipak(packages)
install_github('ramnathv/rCharts')
library(swirl)
swirl()
plot(child ~ parent, galton)
plot(jitter(child,4) ~ parent,galton)
regrline <- lm(child ~ parent, galton)
abline(regrline, lwd=3, col='red')
summary(regrline)
fit <- lm(child ~ parent, galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
lhs-rhs
all.equal(lhs,rhs)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild,varEst+varRes)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
attenu$mag
cov(efit$residuals, attenu$mag)
cov(attenu$mag,efit$residuals)
cov(efit$residuals, attenu$dist)
cor(gpa_nor,gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
fit <- lm(child ~ parent, galton)
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child-mu)^2)
sRes <- deviance(fit)
1-sRes/sTot
summary(fit)$r.squared
cor(galton$parent,galton$child)^2
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent - 1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
head(trees)
fit <- lm(Volume ~ . - 1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2 <- lm(Volume ~ . - 1, trees2)
lapply(list(fit, fit2), coef)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(slidify)
install.packages("Hmisc")
data(mtcars)
data(mtcars)
require(GGally)
install.pakcages(GGally)
install.packages(GGally)
install.packages("GGally")
```{r}
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library(ElemStatLearn)
library(randomForest)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library(ElemStatLearn)
library(randomForest)
library(varImp)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
vowel = rbind(vowel.test,vowel.train)
vowel$y = factor(vowel$y)
vowel.train$y = factor(vowel.train$y)
set.seed(33833)
fit <- randomForest(y~.,data=vowel.train)
imps <- varImp(fit)
order(imps)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# Fit a random forest predictor relating the factor variable y to the remaining variables.
a <- randomForest(y ~ ., data = vowel.train, importance = FALSE)
b <- varImp(a)
order(b)
library(ElemStatLearn)
library(randomForest)
library(caret)
data(vowel.train)
data(vowel.test)
# Set the variable y to be a factor variable in both the training and test set.
# Then set the seed to 33833. Fit (1) a random forest predictor relating the
# factor variable y to the remaining variables and (2) a boosted predictor using
# the "gbm" method. Fit these both with the train() command in the caret package.
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
# create models
fit1 <- train(y ~ ., data = vowel.train, method = "rf", trControl = trainControl(number = 4))
fit2 <- train(y ~ ., data = vowel.train, method = "gbm")
# predict test
predict1 <- predict(fit1, newdata = vowel.test)
predict2 <- predict(fit2, newdata = vowel.test)
# combine predictions
DF_combined <- data.frame(predict1, predict2, y = vowel.test$y)
fit_combined <- train(y ~ ., data = DF_combined, method = "gam")
predict3 <- predict(fit_combined, newdata = vowel.test)
# confusion matrixes
c1 <- confusionMatrix(predict1, vowel.test$y)
c2 <- confusionMatrix(predict2, vowel.test$y)
c3 <- confusionMatrix(predict3, DF_combined$y)
c3
setwd("/Users/pacha/Desktop/base de datos exportadores")library(foreign)
setwd("/Users/pacha/Desktop/base de datos exportadores")library(foreign)
#REEMPLAZAR LAS " SI SE PEGA DESDE EXCELsetwd("/Users/pacha/Desktop/base de datos exportadores")library(foreign)CIUDADES <- read.dbf("CIUDADES.DBF")DIRPAI <- read.dbf("DIRPAI.DBF")EJER_AUX <- read.dbf("EJER_AUX.DBF")EJETEMP <- read.dbf("EJETEMP.DBF")EXPODIRA <- read.dbf("EXPODIRA.DBF")EXPOENCA <- read.dbf("EXPOENCA.DBF")EXPOFONO <- read.dbf("EXPOFONO.DBF")EXPOMAE <- read.dbf("EXPOMAE.DBF")EXPONAB <- read.dbf("EXPONAB.DBF")NEWNAB <- read.dbf("NEWNAB.DBF")RUB_AUX <- read.dbf("RUB_AUX.DBF")SALIDA <- read.dbf("SALIDA.DBF")TABPAI <- read.dbf("TABPAI.DBF")TEMPAI <- read.dbf("TEMPAI.DBF")TEMPORAL <- read.dbf("TEMPORAL.DBF")write.csv(CIUDADES, file = "CIUDADES.csv")write.csv(DIRPAI, file = "DIRPAI.csv")write.csv(EJER_AUX, file = "EJER_AUX.csv")write.csv(EJETEMP, file = "EJETEMP.csv")write.csv(EXPODIRA, file = "EXPODIRA.csv")write.csv(EXPOENCA, file = "EXPOENCA.csv")write.csv(EXPOFONO, file = "EXPOFONO.csv")write.csv(EXPOMAE, file = "EXPOMAE.csv")write.csv(EXPONAB, file = "EXPONAB.csv")write.csv(NEWNAB, file = "NEWNAB.csv")write.csv(RUB_AUX, file = "RUB_AUX.csv")write.csv(SALIDA, file = "SALIDA.csv")write.csv(TABPAI, file = "TABPAI.csv")write.csv(TEMPAI, file = "TEMPAI.csv")write.csv(TEMPORAL, file = "TEMPORAL.csv")
#REEMPLAZAR LAS " SI SE PEGA DESDE EXCELsetwd("/Users/pacha/Desktop/base de datos exportadores")library(foreign)CIUDADES <- read.dbf("CIUDADES.DBF")DIRPAI <- read.dbf("DIRPAI.DBF")EJER_AUX <- read.dbf("EJER_AUX.DBF")EJETEMP <- read.dbf("EJETEMP.DBF")EXPODIRA <- read.dbf("EXPODIRA.DBF")EXPOENCA <- read.dbf("EXPOENCA.DBF")EXPOFONO <- read.dbf("EXPOFONO.DBF")EXPOMAE <- read.dbf("EXPOMAE.DBF")EXPONAB <- read.dbf("EXPONAB.DBF")NEWNAB <- read.dbf("NEWNAB.DBF")RUB_AUX <- read.dbf("RUB_AUX.DBF")SALIDA <- read.dbf("SALIDA.DBF")TABPAI <- read.dbf("TABPAI.DBF")TEMPAI <- read.dbf("TEMPAI.DBF")TEMPORAL <- read.dbf("TEMPORAL.DBF")write.csv(CIUDADES, file = "CIUDADES.csv")write.csv(DIRPAI, file = "DIRPAI.csv")write.csv(EJER_AUX, file = "EJER_AUX.csv")write.csv(EJETEMP, file = "EJETEMP.csv")write.csv(EXPODIRA, file = "EXPODIRA.csv")write.csv(EXPOENCA, file = "EXPOENCA.csv")write.csv(EXPOFONO, file = "EXPOFONO.csv")write.csv(EXPOMAE, file = "EXPOMAE.csv")write.csv(EXPONAB, file = "EXPONAB.csv")write.csv(NEWNAB, file = "NEWNAB.csv")write.csv(RUB_AUX, file = "RUB_AUX.csv")write.csv(SALIDA, file = "SALIDA.csv")write.csv(TABPAI, file = "TABPAI.csv")write.csv(TEMPAI, file = "TEMPAI.csv")write.csv(TEMPORAL, file = "TEMPORAL.csv")
library(foreign)
help(foreign)
??foreign
setwd("/Users/pacha/Desktop/base de datos exportadores")library(foreign)
library(shinyapps)
library(BH)
shinyapps::setAccountInfo(name='pachamaltese', token='0276E1855180CE206ADCFEF6D9C109AC', secret='fyUTO2z7l2fscKBJ9rcbqE3uXPEGeeAZid1Z75G4')
shinyapps::deployApp('/Users/pacha/Documents/Coursera/tareas y controles/Developing Data Products/proyecto/elder-population-chile')
shinyapps::deployApp('/Users/pacha/Documents/Coursera/tareas y controles/Developing Data Products/proyecto')
shinyapps::deployApp('/Users/pacha/Documents/Coursera/tareas y controles/Developing Data Products/proyecto')
# ui.R
library(rCharts)
demografia <- read.csv('instancia.csv')
# Define UI
shinyUI(fluidPage(
# Title
titlePanel("Elder Population (64+ years) Count in Chile (1992-2006)"),
p("According to several studies in Chile we have an aging population and this means to change Public Policy guidelines. In 1995 we had 36 millions of elders in Latin America and by 2025 we will have 72+ millions of elders."),
p("Therefore, it would be interesting to visualize how our elder population is aging. In the pot we can observe that as years are passing, we have more and more 70+ years elders."),
p("The plot shows the elder population (64+ years) classified by age and as females and males (I also show the total population count) from 1992 to 2006."),
p(" "),
em("A good short article about aging population in Chile and Latin America is found in ", a("http://www.gerontologia.uchile.cl/docs/chien3.htm", href="http://www.gerontologia.uchile.cl/docs/chien3.htm")),
p(" "),
em("The data was obtained from the Human Mortality Database:", a("http://www.mortality.org/cgi-bin/hmd/country.php?cntr=CHL&level=1", href="http://www.mortality.org/cgi-bin/hmd/country.php?cntr=CHL&level=1")),
p(" "),
# Sidebar
sidebarLayout(
sidebarPanel(
selectInput(inputId = "Age",
label = "Select an age to display the number of elders of that age:",
choices = c("64",
"65",
"66",
"67",
"68",
"69",
"70",
"71",
"72",
"73",
"74",
"75",
"76",
"77",
"78",
"79",
"80",
"81",
"82",
"83",
"84",
"85",
"86",
"87",
"88",
"89",
"90",
"91",
"92",
"93",
"94",
"95",
"96",
"97",
"98",
"99",
"100",
"101",
"102",
"103",
"104",
"105",
"106",
"107",
"108",
"109",
"110+"),
selected = "64"),
sliderInput("range",
label = "Time period to display:",
min = 1992,
max = 2006,
value = c(1992, 2006),
format = "0000"),
helpText(p("Move the scroll bar to adjust the period of time displayed."), p("Plot Created on 21 Feb 2015 by Pachamaltese"), img(src="https://raw.githubusercontent.com/pachamaltese/Developing-Data-Products/master/proyecto/logo.jpg"), p("This plot was created for JHU's Developing Data Products MOOC."))
),
# Show the plot
mainPanel(
strong("Give the plot a little time to load (the dataset is not small). The chart can be downloaded as PNG, PDF or SVG using the upper right icon in the plot. You can also show/hide series by clicking them below the plot."),
showOutput("lexplot", "highcharts")
)
)
))
library(rCharts)
# ui.R
library(rCharts)
demografia <- read.csv('instancia.csv')
# Define UI
shinyUI(fluidPage(
# Title
titlePanel("Elder Population (64+ years) Count in Chile (1992-2006)"),
p("According to several studies in Chile we have an aging population and this means to change Public Policy guidelines. In 1995 we had 36 millions of elders in Latin America and by 2025 we will have 72+ millions of elders."),
p("Therefore, it would be interesting to visualize how our elder population is aging. In the pot we can observe that as years are passing, we have more and more 70+ years elders."),
p("The plot shows the elder population (64+ years) classified by age and as females and males (I also show the total population count) from 1992 to 2006."),
p(" "),
em("A good short article about aging population in Chile and Latin America is found in ", a("http://www.gerontologia.uchile.cl/docs/chien3.htm", href="http://www.gerontologia.uchile.cl/docs/chien3.htm")),
p(" "),
em("The data was obtained from the Human Mortality Database:", a("http://www.mortality.org/cgi-bin/hmd/country.php?cntr=CHL&level=1", href="http://www.mortality.org/cgi-bin/hmd/country.php?cntr=CHL&level=1")),
p(" "),
# Sidebar
sidebarLayout(
sidebarPanel(
selectInput(inputId = "Age",
label = "Select an age to display the number of elders of that age:",
choices = c("64",
"65",
"66",
"67",
"68",
"69",
"70",
"71",
"72",
"73",
"74",
"75",
"76",
"77",
"78",
"79",
"80",
"81",
"82",
"83",
"84",
"85",
"86",
"87",
"88",
"89",
"90",
"91",
"92",
"93",
"94",
"95",
"96",
"97",
"98",
"99",
"100",
"101",
"102",
"103",
"104",
"105",
"106",
"107",
"108",
"109",
"110+"),
selected = "64"),
sliderInput("range",
label = "Time period to display:",
min = 1992,
max = 2006,
value = c(1992, 2006),
format = "0000"),
helpText(p("Move the scroll bar to adjust the period of time displayed."), p("Plot Created on 21 Feb 2015 by Pachamaltese"), img(src="https://raw.githubusercontent.com/pachamaltese/Developing-Data-Products/master/proyecto/logo.jpg"), p("This plot was created for JHU's Developing Data Products MOOC."))
),
# Show the plot
mainPanel(
strong("Give the plot a little time to load (the dataset is not small). The chart can be downloaded as PNG, PDF or SVG using the upper right icon in the plot. You can also show/hide series by clicking them below the plot."),
showOutput("lexplot", "highcharts")
)
)
))
# server.R
library(rCharts)
demografia <- read.csv('instancia.csv')
options(RCHART_WIDTH = 500)
shinyServer(function(input, output) {
output$lexplot <- renderChart2({
selected <- input$Age
Age <- subset(demografia, Age == selected & Year %in% seq(input$range[1], input$range[2], 1))
grafico <- hPlot(
x = "Year",
y = "People",
group = "Gender",
data = Age,
type = "spline")
grafico$yAxis(title = list(enabled = TRUE, text = 'Population count'),
labels = list(rotation = -0, align = 'right'),
replace = T)
grafico$xAxis(title = list(enabled = TRUE, text = 'Year'), labels = list(rotation = -30, align = 'right'), replace = T)
grafico$exporting(enabled = T)
return(grafico)
})
})
shinyapps::deployApp('/Users/pacha/Documents/Coursera/tareas y controles/Developing Data Products/proyecto')
set.seed(3523)library(AppliedPredictiveModeling)data(concrete)inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]] training = concrete[ inTrain,]testing = concrete[-inTrain,]
library(caret)library(gbm)set.seed(3523)library(AppliedPredictiveModeling)data(concrete)inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]] training = concrete[ inTrain,]testing = concrete[-inTrain,]
library(caret)
library(gbm)
set.seed(3523)library(AppliedPredictiveModeling)data(concrete)inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]] training = concrete[ inTrain,]testing = concrete[-inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]] training = concrete[ inTrain,]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
testing
training
fit <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(fit$finalModel, xvar = "penalty", use.color = TRUE)
setwd("/Users/pacha/Documents/Coursera/tareas y controles/Practical Machine Learning/proyecto")
load <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
sessionInfo()
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot", "car")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot", "xtable")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot", "quantmod")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot", "ggmap")
load(packages)
packages <- c("data.table", "caret", "randomForest", "foreach", "rpart", "rpart.plot", "corrplot", "ggmap")
load(packages)
remove.packages(ggmap)
remove.packages(ggmap, libs)
remove.packages(ggmap)
remove.packages(ggmap, lib)
?remove.packages
remove.packages(ggmap, )
remove.packages(ggmap)
remove.packages(maps)
remove.packages(sp)
remove.packages(sp,libs)
remove.packages(sp, lib)
remove.packages(sp)
remove.packages(RgoogleMaps)
remove.packages(mapproj)
remove.packages(mapproj, )
remove.packages(mapproj, lib)
remove.packages(mapproj)
remove.packages(geosphere)
remove.packages(geosphere, .libPaths())
remove.packages(mapproj, .libPaths())
